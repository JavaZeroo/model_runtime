{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljb/miniconda3/envs/ai/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ljb/miniconda3/envs/ai/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ljb/miniconda3/envs/ai/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/home/ljb/miniconda3/envs/ai/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from pandas.core.common import flatten\n",
    "# importing obg datatset\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "from pandas.core.common import flatten\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
    "sns.set_theme(style=\"ticks\")\n",
    "import collections\n",
    "from scipy.special import softmax\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Train data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Train data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Validation data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Validation data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading Test data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading Test data\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from rich import print\n",
    "DATA_ROOT = Path('kaggle_data')\n",
    "\n",
    "print('Loading Train data...')\n",
    "ndf_files_train = list((DATA_ROOT / 'npz_all/npz/layout/nlp/default/train').iterdir())\n",
    "nrd_files_train = list((DATA_ROOT / 'npz_all/npz/layout/nlp/random/train').iterdir())\n",
    "xdf_files_train = list((DATA_ROOT / 'npz_all/npz/layout/xla/default/train').iterdir())\n",
    "xrd_files_train = list((DATA_ROOT / 'npz_all/npz/layout/xla/random/train').iterdir())\n",
    "\n",
    "ndf_nps_train = [np.load(f) for f in ndf_files_train]\n",
    "nrd_nps_train = [np.load(f) for f in nrd_files_train]\n",
    "xdf_nps_train = [np.load(f) for f in xdf_files_train]\n",
    "xrd_nps_train = [np.load(f) for f in xrd_files_train]\n",
    "\n",
    "print('Loading Validation data...')\n",
    "ndf_files_valid = list((DATA_ROOT / 'npz_all/npz/layout/nlp/default/valid').iterdir())\n",
    "nrd_files_valid = list((DATA_ROOT / 'npz_all/npz/layout/nlp/random/valid').iterdir())\n",
    "xdf_files_valid = list((DATA_ROOT / 'npz_all/npz/layout/xla/default/valid').iterdir())\n",
    "xrd_files_valid = list((DATA_ROOT / 'npz_all/npz/layout/xla/random/valid').iterdir())\n",
    "\n",
    "ndf_nps_valid = [np.load(f) for f in ndf_files_valid]\n",
    "nrd_nps_valid = [np.load(f) for f in nrd_files_valid]\n",
    "xdf_nps_valid = [np.load(f) for f in xdf_files_valid]\n",
    "xrd_nps_valid = [np.load(f) for f in xrd_files_valid]\n",
    "\n",
    "print('Loading Test data...')\n",
    "ndf_files_test = list((DATA_ROOT / 'npz_all/npz/layout/nlp/default/test').iterdir())\n",
    "nrd_files_test = list((DATA_ROOT / 'npz_all/npz/layout/nlp/random/test').iterdir())\n",
    "xdf_files_test = list((DATA_ROOT / 'npz_all/npz/layout/xla/default/test').iterdir())\n",
    "xrd_files_test = list((DATA_ROOT / 'npz_all/npz/layout/xla/random/test').iterdir())\n",
    "\n",
    "ndf_nps_test = [np.load(f) for f in ndf_files_test]\n",
    "nrd_nps_test = [np.load(f) for f in nrd_files_test]\n",
    "xdf_nps_test = [np.load(f) for f in xdf_files_test]\n",
    "xrd_nps_test = [np.load(f) for f in xrd_files_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        # `train_loader` computes the k-hop neighborhood of a batch of nodes,\n",
    "        # and returns, for each layer, a bipartite graph object, holding the\n",
    "        # bipartite edges `edge_index`, the index `e_id` of the original edges,\n",
    "        # and the size/shape `size` of the bipartite graph.\n",
    "        # Target nodes are also included in the source nodes so that one can\n",
    "        # easily apply skip-connections or add self-loops.\n",
    "        layer_1_embeddings, layer_2_embeddings, layer_3_embeddings = None, None, None\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            xs = []\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first.\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "            xs.append(x)\n",
    "            if i == 0: \n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_1_embeddings = x_all\n",
    "            elif i == 1:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_2_embeddings = x_all\n",
    "            elif i == 2:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_3_embeddings = x_all    \n",
    "        #return x.log_softmax(dim=-1)\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
    "\n",
    "    def inference(self, x_all):\n",
    "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
    "        pbar.set_description('Evaluating')\n",
    "\n",
    "        # Compute representations of nodes layer by layer, using *all*\n",
    "        # available edges. This leads to faster computation in contrast to\n",
    "        # immediately computing the final representations of each batch.\n",
    "        total_edges = 0\n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                edge_index, _, size = adj.to(device)\n",
    "                total_edges += edge_index.size(1)\n",
    "                x = x_all[n_id].to(device)\n",
    "                x_target = x[:size[1]]\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "                if i != self.num_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                xs.append(x)\n",
    "\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "            if i == 0: \n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_1_embeddings = x_all\n",
    "            elif i == 1:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_2_embeddings = x_all\n",
    "            elif i == 2:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_3_embeddings = x_all\n",
    "                \n",
    "        pbar.close()\n",
    "\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
    "def aggregate_outputs(out):\n",
    "    # Example: simple average\n",
    "    return sum(out) / len(out)\n",
    "\n",
    "class myModel(torch.nn.Module):\n",
    "    def  __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.SAGE = SAGE(*args)\n",
    "        self.config_fc = torch.nn.Linear(88 * 18, 64)  # Flatten and map to 64-dim\n",
    "        self.final_fc = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, adjs, config_feat):\n",
    "        out = self.SAGE(x, adjs)\n",
    "        for o in out:\n",
    "            print(o.shape)\n",
    "        aggregated_sage_output = aggregate_outputs(out)\n",
    "        print(aggregated_sage_output.shape)\n",
    "        config_feat  = config_feat.view(1000, -1)\n",
    "        processed_config_feat = self.config_fc(config_feat)\n",
    "        combined_feat = torch.cat([aggregated_sage_output, processed_config_feat], dim=1)\n",
    "        final_output = self.final_fc(combined_feat)\n",
    "        return final_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_feat'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1696</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_opcode'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1696</span>,<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'edge_index'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2697</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_config_feat'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100040</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_config_ids'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">121</span>,<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'config_runtime'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100040</span>,<span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'node_splits'</span>: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'node_feat'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1696\u001b[0m, \u001b[1;36m140\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'node_opcode'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1696\u001b[0m,\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'edge_index'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m2697\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'node_config_feat'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m100040\u001b[0m, \u001b[1;36m121\u001b[0m, \u001b[1;36m18\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'node_config_ids'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m121\u001b[0m,\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'config_runtime'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m100040\u001b[0m,\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'node_splits'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_npz_shape(npz_file):\n",
    "    keys_and_shapes = {key: npz_file[key].shape for key in npz_file.keys()}\n",
    "    print(keys_and_shapes)\n",
    "check_npz_shape(ndf_nps_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47712</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m47712\u001b[0m, \u001b[1;36m26\u001b[0m, \u001b[1;36m18\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m372\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m372\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m372\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m372\u001b[0m, \u001b[1;36m64\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1000, -1]' is invalid for input of size 22329216",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[39m# 计算损失、反向传播、更新等（这取决于你的具体任务和损失函数）\u001b[39;00m\n\u001b[1;32m     45\u001b[0m             \u001b[39m# ...\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m train(\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 41\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     38\u001b[0m     x_batch \u001b[39m=\u001b[39m x[n_id]\u001b[39m.\u001b[39mto(device)  \u001b[39m# n_id是这个批次中所有节点的id\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39m# 前向传播\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     out \u001b[39m=\u001b[39m model(x_batch, adjs, config_feat)\n\u001b[1;32m     42\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m, in \u001b[0;36mmyModel.forward\u001b[0;34m(self, x, adjs, config_feat)\u001b[0m\n\u001b[1;32m     95\u001b[0m aggregated_sage_output \u001b[39m=\u001b[39m aggregate_outputs(out)\n\u001b[1;32m     96\u001b[0m \u001b[39mprint\u001b[39m(aggregated_sage_output\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 97\u001b[0m config_feat  \u001b[39m=\u001b[39m config_feat\u001b[39m.\u001b[39mview(\u001b[39m1000\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m processed_config_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_fc(config_feat)\n\u001b[1;32m     99\u001b[0m combined_feat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([aggregated_sage_output, processed_config_feat], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1000, -1]' is invalid for input of size 22329216"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import NeighborSampler\n",
    "\n",
    "dataset = xdf_nps_train #+ xrd_nps_train + ndf_nps_train + nrd_nps_train\n",
    "device = 'cpu'\n",
    "# 初始化NeighborSampler\n",
    "sampler = NeighborSampler(\n",
    "    edge_index=torch.tensor(dataset[0]['edge_index']),\n",
    "    sizes=[15, 10, 5],  # 这里的sizes是一个列表，表示每一层的邻居采样数\n",
    "    batch_size=2000,  # 每个批次中的节点数\n",
    "    shuffle=True,    # 是否打乱节点\n",
    "    num_workers=0    # 数据加载的并行度\n",
    ")\n",
    "# Initialize the model\n",
    "in_channels = 140\n",
    "hidden_channels = 64  # This is just an example, can be tuned\n",
    "out_channels = 1  # This can be tuned based on the specific task\n",
    "num_layers = 3\n",
    "\n",
    "model = myModel(in_channels, hidden_channels, out_channels, num_layers)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# 数据迭代和模型训练\n",
    "def train(epoch):\n",
    "    for data in dataset:  # Assume `dataset` is an iterable of graph data dictionaries\n",
    "        x = torch.tensor(data['node_feat'], dtype=torch.float).to(device)  # 假设device是你的计算设备（CPU或GPU）\n",
    "        edge_index = torch.tensor(data['edge_index'], dtype=torch.long).to(device)\n",
    "        config_feat = torch.tensor(data['node_config_feat'], dtype=torch.float).to(device)\n",
    "        print(config_feat.shape)\n",
    "        # 更新NeighborSampler的edge_index\n",
    "        sampler.edge_index = edge_index\n",
    "\n",
    "        # Forward and backward passes\n",
    "        for batch_size, n_id, adjs in sampler:\n",
    "            # adjs已经是一个列表，其中包含了多跳邻居的信息\n",
    "            \n",
    "            # 对于每个批次，获取相应的节点特征\n",
    "            x_batch = x[n_id].to(device)  # n_id是这个批次中所有节点的id\n",
    "\n",
    "            # 前向传播\n",
    "            out = model(x_batch, adjs, config_feat)\n",
    "            break\n",
    "        break\n",
    "            # 计算损失、反向传播、更新等（这取决于你的具体任务和损失函数）\n",
    "            # ...\n",
    "    return None\n",
    "\n",
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
